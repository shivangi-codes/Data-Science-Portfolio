{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71a3dbd1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the dataset:\n",
      "   Unnamed: 0                                               Data       Labels\n",
      "0           0  Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:49...  alt.atheism\n",
      "1           1  Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:51...  alt.atheism\n",
      "2           2  Newsgroups: alt.atheism\\nPath: cantaloupe.srv....  alt.atheism\n",
      "3           3  Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:51...  alt.atheism\n",
      "4           4  Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:51...  alt.atheism\n",
      "\n",
      "Data structure:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19997 entries, 0 to 19996\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  19997 non-null  int64 \n",
      " 1   Data        19997 non-null  object\n",
      " 2   Labels      19997 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 468.8+ KB\n",
      "None\n",
      "\n",
      "TF-IDF Features:\n",
      "  (0, 210183)\t0.015038450321698189\n",
      "  (0, 66915)\t0.03030618023425967\n",
      "  (0, 136860)\t0.010273709705516762\n",
      "  (0, 215420)\t0.012857663329378537\n",
      "  (0, 65474)\t0.031033817993205544\n",
      "  (0, 162595)\t0.02603878307852523\n",
      "  (0, 220096)\t0.025666012994814975\n",
      "  (0, 142665)\t0.011037262604562349\n",
      "  (0, 126254)\t0.01413679655713494\n",
      "  (0, 66144)\t0.016879922350186493\n",
      "  (0, 59820)\t0.029711656896203305\n",
      "  (0, 65469)\t0.020774187357458507\n",
      "  (0, 96704)\t0.02106749510917746\n",
      "  (0, 163366)\t0.03197190622051426\n",
      "  (0, 220418)\t0.015788811869407542\n",
      "  (0, 65456)\t0.01917219337691182\n",
      "  (0, 162597)\t0.031033817993205544\n",
      "  (0, 223492)\t0.012939110515202903\n",
      "  (0, 239211)\t0.012964586039242365\n",
      "  (0, 119991)\t0.014556557820211978\n",
      "  (0, 230783)\t0.015463540719531613\n",
      "  (0, 71177)\t0.03197190622051426\n",
      "  (0, 172598)\t0.01312848236788408\n",
      "  (0, 101082)\t0.023214640014680644\n",
      "  (0, 119806)\t0.02719040026924563\n",
      "  :\t:\n",
      "  (19996, 128696)\t0.07617126080182436\n",
      "  (19996, 250853)\t0.08342812576836992\n",
      "  (19996, 168815)\t0.05971415395922936\n",
      "  (19996, 116942)\t0.050554179697887835\n",
      "  (19996, 124917)\t0.07756834429557395\n",
      "  (19996, 66130)\t0.028206607098397358\n",
      "  (19996, 239211)\t0.06278569970391389\n",
      "  (19996, 239409)\t0.038452591023178974\n",
      "  (19996, 150551)\t0.035143763785330254\n",
      "  (19996, 141170)\t0.059411183542645594\n",
      "  (19996, 210945)\t0.10010514970040178\n",
      "  (19996, 113433)\t0.08843565711937316\n",
      "  (19996, 206029)\t0.08693767720774176\n",
      "  (19996, 254019)\t0.05633113290334907\n",
      "  (19996, 154400)\t0.01583771607507425\n",
      "  (19996, 193588)\t0.016443151143834413\n",
      "  (19996, 64507)\t0.017109594034726477\n",
      "  (19996, 22547)\t0.022313789360102438\n",
      "  (19996, 111845)\t0.01579184858736955\n",
      "  (19996, 169831)\t0.01579184858736955\n",
      "  (19996, 230983)\t0.01579184858736955\n",
      "  (19996, 188106)\t0.01579184858736955\n",
      "  (19996, 196272)\t0.01579184858736955\n",
      "  (19996, 80451)\t0.034669562108056225\n",
      "  (19996, 255794)\t0.034661734673651926\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "import string\n",
    "\n",
    "# Step 1: Data Loading and Initial Exploration\n",
    "file_path = \"C:/Users/shiva/Downloads/Naive Bayes and Text Mining/Naive Bayes and Text Mining/blogs_categories.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Displaying the first few rows of the dataframe and checking its structure\n",
    "print(\"First few rows of the dataset:\")\n",
    "print(df.head())\n",
    "print(\"\\nData structure:\")\n",
    "print(df.info())\n",
    "\n",
    "# Step 2: Data Preprocessing\n",
    "def preprocess_text(text):\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "# Apply text preprocessing\n",
    "df['clean_text'] = df['Data'].apply(preprocess_text)\n",
    "\n",
    "# Step 3: Feature Extraction (TF-IDF)\n",
    "# Define custom stop words including English stop words and any additional ones specific to the task\n",
    "custom_stopwords = list(ENGLISH_STOP_WORDS)\n",
    "# Define TF-IDF vectorizer with custom preprocessed text and custom stop words\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=custom_stopwords)\n",
    "\n",
    "# Fit and transform the preprocessed text data into TF-IDF features\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(df['clean_text'])\n",
    "\n",
    "# Display the TF-IDF features\n",
    "print(\"\\nTF-IDF Features:\")\n",
    "print(tfidf_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "039953e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.73      0.79      0.76       173\n",
      "           comp.graphics       0.87      0.91      0.89       179\n",
      " comp.os.ms-windows.misc       0.93      0.88      0.91       226\n",
      "comp.sys.ibm.pc.hardware       0.85      0.85      0.85       204\n",
      "   comp.sys.mac.hardware       0.88      0.96      0.92       205\n",
      "          comp.windows.x       0.97      0.94      0.96       186\n",
      "            misc.forsale       0.90      0.79      0.84       190\n",
      "               rec.autos       0.92      0.95      0.93       203\n",
      "         rec.motorcycles       1.00      0.97      0.98       218\n",
      "      rec.sport.baseball       0.99      0.98      0.99       192\n",
      "        rec.sport.hockey       0.97      0.99      0.98       203\n",
      "               sci.crypt       0.91      0.98      0.95       200\n",
      "         sci.electronics       0.94      0.89      0.91       227\n",
      "                 sci.med       1.00      0.95      0.98       196\n",
      "               sci.space       0.96      0.97      0.96       205\n",
      "  soc.religion.christian       0.91      1.00      0.95       215\n",
      "      talk.politics.guns       0.86      0.91      0.88       205\n",
      "   talk.politics.mideast       0.92      0.94      0.93       197\n",
      "      talk.politics.misc       0.77      0.76      0.76       200\n",
      "      talk.religion.misc       0.61      0.49      0.54       176\n",
      "\n",
      "                accuracy                           0.90      4000\n",
      "               macro avg       0.89      0.89      0.89      4000\n",
      "            weighted avg       0.90      0.90      0.90      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Step 1: Split the data into training and test sets\n",
    "X = tfidf_features\n",
    "y = df['Labels']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Implement a Naive Bayes classifier\n",
    "naive_bayes_classifier = MultinomialNB()\n",
    "\n",
    "# Step 3: Train the model on the training set\n",
    "naive_bayes_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Make predictions on the test set\n",
    "predictions = naive_bayes_classifier.predict(X_test)\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccfa0e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Distribution across Different Categories:\n",
      "Sentiment                 Negative  Neutral  Positive\n",
      "Labels                                               \n",
      "alt.atheism                    366        7       627\n",
      "comp.graphics                  112       44       844\n",
      "comp.os.ms-windows.misc        180       42       778\n",
      "comp.sys.ibm.pc.hardware       191       17       792\n",
      "comp.sys.mac.hardware          231       46       723\n",
      "comp.windows.x                 216       41       743\n",
      "misc.forsale                   129       65       806\n",
      "rec.autos                      299       22       679\n",
      "rec.motorcycles                285       18       697\n",
      "rec.sport.baseball             212       36       752\n",
      "rec.sport.hockey               248       12       740\n",
      "sci.crypt                      304        6       690\n",
      "sci.electronics                183       29       788\n",
      "sci.med                        318       21       661\n",
      "sci.space                      255       18       727\n",
      "soc.religion.christian         241        0       756\n",
      "talk.politics.guns             654       10       336\n",
      "talk.politics.mideast          652        5       343\n",
      "talk.politics.misc             520        3       477\n",
      "talk.religion.misc             382        7       611\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"C:/Users/shiva/Downloads/Naive Bayes and Text Mining/Naive Bayes and Text Mining/blogs_categories.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Now you can proceed with the sentiment analysis code\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Step 1: Initialize the VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Step 2: Define a function to perform sentiment analysis on each blog post\n",
    "def analyze_sentiment(text):\n",
    "    sentiment_score = analyzer.polarity_scores(text)\n",
    "    compound_score = sentiment_score['compound']\n",
    "    if compound_score >= 0.05:\n",
    "        return 'Positive'\n",
    "    elif compound_score <= -0.05:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "# Step 3: Apply sentiment analysis to the blog posts and create a new column for sentiment\n",
    "df['Sentiment'] = df['Data'].apply(analyze_sentiment)\n",
    "\n",
    "# Step 4: Examine the distribution of sentiments across different categories\n",
    "sentiment_distribution = df.groupby(['Labels', 'Sentiment']).size().unstack(fill_value=0)\n",
    "print(\"Sentiment Distribution across Different Categories:\")\n",
    "print(sentiment_distribution)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9473ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: vaderSentiment in c:\\users\\shiva\\appdata\\roaming\\python\\python311\\site-packages (3.3.2)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from vaderSentiment) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pip install vaderSentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5269cd3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classifier Performance:\n",
      "Accuracy: 0.89175\n",
      "Precision: 0.8929008949579103\n",
      "Recall: 0.89175\n",
      "F1-score: 0.8911821637029316\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"C:/Users/shiva/Downloads/Naive Bayes and Text Mining/Naive Bayes and Text Mining/blogs_categories.csv\")\n",
    "\n",
    "# Step 1: Preprocess Text Data\n",
    "# Assuming 'Data' column contains the text data\n",
    "# Here, we'll use TF-IDF vectorization\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df['Data'])\n",
    "y = df['Labels']\n",
    "\n",
    "# Step 2: Split Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Train Model\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Make Predictions\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "\n",
    "# Step 5: Evaluate Performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"Naive Bayes Classifier Performance:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n",
    "\n",
    "# Step 6: Reflect on Sentiment Analysis\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "sentiments = []\n",
    "\n",
    "for text in df['Data']:\n",
    "    sentiment = analyzer.polarity_scores(text)\n",
    "    sentiments.append(sentiment)\n",
    "\n",
    "# Step 7: Analyze Sentiment Distribution\n",
    "# You can further analyze the sentiments list to examine the distribution across different categories and summarize your findings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf4df79",
   "metadata": {},
   "outputs": [],
   "source": [
    "To evaluate the performance of the Naive Bayes classifier and discuss the results, let's analyze the metrics and reflect on the sentiment analysis results:\n",
    "\n",
    "### Evaluation of Naive Bayes Classifier:\n",
    "\n",
    "1. **Accuracy:** It measures the overall correctness of the classifier's predictions.\n",
    "2. **Precision:** It indicates the proportion of correctly predicted instances among all instances classified as positive by the model.\n",
    "3. **Recall:** It represents the proportion of correctly predicted instances among all actual positive instances.\n",
    "4. **F1-score:** It is the harmonic mean of precision and recall, providing a balance between the two metrics.\n",
    "\n",
    "### Discussion of Model Performance:\n",
    "\n",
    "After evaluating the classifier using these metrics, we can interpret the results as follows:\n",
    "\n",
    "- **Accuracy:** The accuracy score gives an overall view of how well the model performs across all classes. A higher accuracy score indicates better performance.\n",
    "- **Precision and Recall:** Precision and recall are important when dealing with imbalanced datasets or when certain classes are more critical than others. We should consider both precision and recall to understand the classifier's ability to correctly identify instances of each class.\n",
    "- **Challenges:** Challenges encountered during the classification process might include handling imbalanced datasets, selecting appropriate features, and optimizing hyperparameters to improve model performance.\n",
    "\n",
    "### Reflection on Sentiment Analysis Results:\n",
    "\n",
    "- The sentiment analysis results provide insights into the emotional tone of the blog posts.\n",
    "- By examining the sentiment distribution across different categories, we can identify trends or patterns in the sentiment expressed in the blog posts.\n",
    "- Understanding the sentiment of blog posts can help in various applications such as understanding customer feedback, monitoring public opinion, or analyzing social media content.\n",
    "\n",
    "In summary, evaluating the performance of the Naive Bayes classifier provides insights into its effectiveness in classifying blog posts. Reflecting on sentiment analysis results helps in understanding the emotional context of the content, which can be valuable for various applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}


# Data Science Portfolio

Welcome to my Data Science Portfolio! This repository showcases various machine learning techniques applied in data science through a collection of Jupyter notebooks. Each notebook demonstrates my skills in data analysis, machine learning, and statistical modeling, providing a comprehensive overview of my capabilities in the field.

## Contents

- [Artificial Neural Networks (ANN)](#artificial-neural-networks-ann)
- [Association Rules](#association-rules)
- [Clustering Analysis](#clustering-analysis)
- [Decision Trees](#decision-trees)
- [Multilinear Regression](#multilinear-regression)
- [Neural Networks](#neural-networks)
- [Principal Component Analysis (PCA)](#principal-component-analysis-pca)
- [Extreme Gradient Boosting (XGBoost)](#extreme-gradient-boosting-xgboost)
- [Exploratory Data Analysis (EDA) on Cardiovascular Diseases](#exploratory-data-analysis-eda-on-cardiovascular-diseases)
- [Chi-Square Test](#chi-square-test)
- [Hypothesis Testing](#hypothesis-testing)
- [K-Nearest Neighbors (KNN)](#k-nearest-neighbors-knn)
- [Naive Bayes Classifier](#naive-bayes-classifier)
- [Random Forest](#random-forest)
- [Recommendation System](#recommendation-system)
- [Support Vector Machine (SVM)](#support-vector-machine-svm)
- [Time Series Analysis](#time-series-analysis)
- [Statistics in Data Science](#statistics-in-data-science)
- [Types of Data in Data Science](#types-of-data-in-data-science)

## Projects

### Artificial Neural Networks (ANN)
This notebook explores the application of artificial neural networks in predictive modeling. It covers the implementation of a simple ANN from scratch using Python and TensorFlow/Keras.

### Association Rules
The Association Rules notebook demonstrates the use of association rule mining to discover interesting relationships between variables in large datasets. Techniques such as Apriori and FP-Growth are explored.

### Clustering Analysis
In this notebook, various clustering techniques, including K-Means and Hierarchical Clustering, are applied to segment data into meaningful groups. The analysis includes visualizations and interpretations of the clusters formed.

### Decision Trees
This project involves building and evaluating decision tree models for classification tasks. It includes discussions on tree pruning, feature importance, and model interpretability.

### Multilinear Regression
The Multilinear Regression notebook presents the use of multiple linear regression to model the relationship between a dependent variable and multiple independent variables. The notebook includes assumptions checking and model diagnostics.

### Neural Networks
An extension of the ANN notebook, this project delves deeper into neural network architectures, including Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs).

### Principal Component Analysis (PCA)
PCA is a dimensionality reduction technique used to reduce the number of variables in a dataset while preserving as much information as possible. This notebook demonstrates PCA with practical examples and visualizations.

### Extreme Gradient Boosting (XGBoost)
XGBoost is a powerful machine learning algorithm used for classification and regression tasks. This notebook showcases the application of XGBoost with parameter tuning and model evaluation.

### Exploratory Data Analysis (EDA) on Cardiovascular Diseases
This notebook provides a thorough EDA on a dataset related to cardiovascular diseases. It includes data cleaning, visualization, and initial insights that guide further analysis.

### Chi-Square Test
The Chi-Square Test notebook explains the implementation and interpretation of chi-square tests for independence and goodness of fit. Practical examples with real datasets are provided.

### Hypothesis Testing
This project involves various statistical hypothesis tests, including t-tests, ANOVA, and non-parametric tests. Each test is explained with examples and step-by-step calculations.

### K-Nearest Neighbors (KNN)
KNN is a simple, non-parametric classification algorithm. This notebook covers the implementation of KNN, hyperparameter tuning, and evaluation metrics.

### Naive Bayes Classifier
The Naive Bayes Classifier notebook demonstrates the use of this probabilistic classifier for text classification tasks, such as spam detection.

### Random Forest
Random Forest is an ensemble learning method for classification and regression. This notebook covers the implementation, parameter tuning, and feature importance of Random Forest models.

### Recommendation System
This project involves building a recommendation system using collaborative filtering and content-based filtering techniques. The notebook includes data preprocessing, model building, and evaluation.

### Support Vector Machine (SVM)
The SVM notebook explores the use of support vector machines for classification tasks. It includes kernel tricks, parameter tuning, and performance evaluation.

### Time Series Analysis
Time series analysis involves analyzing temporal data to extract meaningful statistics and identify patterns. This notebook covers various time series models, including ARIMA and Exponential Smoothing.

### Statistics in Data Science
This document provides a comprehensive overview of statistical methods and their applications in data science, including descriptive statistics, inferential statistics, and probability distributions.

### Types of Data in Data Science
An exploration of different types of data encountered in data science, such as structured, unstructured, and semi-structured data, and their respective handling techniques.

## How to Use This Repository

1. **Clone the repository**:
   ```sh
   git clone [https://github.com/yourusername/data-science-portfolio.git](https://github.com/shivangi-codes/Data-Science-Portfolio)
   ```
2. **Navigate to the project directory**:
   ```sh
   cd data-science-portfolio
   ```
3. **Install the required dependencies**:
   Most notebooks use common data science libraries such as `numpy`, `pandas`, `scikit-learn`, and `matplotlib`. You can install these dependencies using:
   ```sh
   pip install -r requirements.txt
   ```
4. **Run the notebooks**:
   Open the Jupyter notebooks using Jupyter Notebook or Jupyter Lab and run the cells to see the code in action.

## Conclusion

This portfolio is a demonstration of my data science skills and my ability to apply machine learning techniques to solve real-world problems. Each project includes detailed documentation, code, and visualizations to provide a clear understanding of the methods used and the results obtained.

Feel free to explore the projects, and do not hesitate to reach out if you have any questions or feedback!

